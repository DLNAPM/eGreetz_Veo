
import {
  GoogleGenAI,
  Modality,
  VideoGenerationReferenceType,
} from '@google/genai';
import { GenerateGreetingParams, VoiceGender, VeoModel } from '../types';

/**
 * Helper to decode base64 audio and get its duration in seconds.
 * Gemini TTS output is raw PCM (no header).
 * Assuming 16-bit mono PCM at 24kHz (2 bytes per sample).
 */
async function getAudioDuration(base64Data: string): Promise<number> {
  try {
    const binaryString = atob(base64Data);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    
    // Formula: total_bytes / (bytes_per_sample * samples_per_second)
    const duration = (bytes.length / 2) / 24000; 
    return duration;
  } catch (e) {
    console.warn("Could not determine exact audio duration, defaulting to 8s", e);
    return 8;
  }
}

/**
 * Generates a cinematic greeting video using Gemini Veo models.
 * Dynamically adjusts length to be synchronized with the generated audio script.
 */
export const generateGreetingVideo = async (
  params: GenerateGreetingParams & { audioDuration?: number }
): Promise<{ objectUrl: string; blob: Blob }> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
  
  // Calculate the target duration based on the actual audio script length plus padding
  const audioDuration = params.audioDuration || 7;
  let targetDuration = Math.ceil(audioDuration) + 3; // Add 3s padding for a comfortable finish
  
  // If "Director's Cut" is selected, we ensure the video is at least 15 seconds
  // But if the script is longer, we follow the script duration.
  if (params.extended) {
    targetDuration = Math.max(targetDuration, 15);
  }

  const standardSegmentDuration = 7;
  const needsExtension = targetDuration > standardSegmentDuration;

  /**
   * CRITICAL: If any extension is anticipated, the initial segment MUST use
   * 'veo-3.1-generate-preview' (not the fast model) to ensure the generated 
   * asset is compatible with the extension endpoint.
   */
  const modelToUse = (needsExtension || params.userPhoto) 
    ? 'veo-3.1-generate-preview' 
    : params.model;

  const visualContext = params.scenicDescription && params.scenicDescription.trim().length > 0 
    ? `Visual Scene: ${params.scenicDescription}` 
    : `Visual Theme: ${params.theme}`;

  const cinematicPrompt = `
    A cinematic, high-quality holiday greeting video for ${params.occasion}.
    ${visualContext}. 
    Atmosphere: Joyful, celebratory, professional cinematic lighting, 8k resolution feel.
    Context: ${params.message.substring(0, 300)}
  `.trim();

  // Extensions currently require 720p resolution
  const config: any = {
    numberOfVideos: 1,
    resolution: '720p',
    aspectRatio: params.userPhoto ? '16:9' : params.aspectRatio,
  };

  const initialPayload: any = {
    model: modelToUse,
    prompt: cinematicPrompt,
    config: config,
  };

  if (params.userPhoto) {
    initialPayload.config.referenceImages = [{
      image: {
        imageBytes: params.userPhoto.base64,
        mimeType: params.userPhoto.file.type || 'image/jpeg',
      },
      referenceType: VideoGenerationReferenceType.ASSET,
    }];
  }

  try {
    console.log(`Starting production. Audio duration: ${audioDuration}s. Target video duration: ${targetDuration}s.`);
    
    // 1. Generate the initial 7s segment
    let operation = await ai.models.generateVideos(initialPayload);

    while (!operation.done) {
      await new Promise((resolve) => setTimeout(resolve, 10000));
      operation = await ai.operations.getVideosOperation({ operation: operation });
    }

    let currentVideo = operation.response?.generatedVideos?.[0]?.video;
    if (!currentVideo) throw new Error("Initial video generation failed to return an asset.");
    
    let currentVideoDuration = standardSegmentDuration;
    
    // 2. Iteratively extend the video until targetDuration is satisfied
    // Each extension typically adds about 7 seconds of new footage.
    while (currentVideoDuration < targetDuration) {
      console.log(`Extending production. Current duration: ${currentVideoDuration}s. Goal: ${targetDuration}s.`);
      
      /**
       * INCREASED DELAY: The "Input video must be a video that was generated by VEO that has been processed" 
       * error often occurs because the newly generated URI isn't yet fully indexed for extension.
       */
      await new Promise((resolve) => setTimeout(resolve, 10000));

      const extensionPayload = {
        model: 'veo-3.1-generate-preview',
        prompt: `Continue the beautiful cinematic celebration for ${params.occasion}. The scene flows seamlessly into an evolving visual masterpiece, maintaining perfect stylistic, character, and environmental consistency. High fidelity celebratory details.`,
        video: currentVideo,
        config: {
          numberOfVideos: 1,
          resolution: '720p',
          aspectRatio: config.aspectRatio,
        }
      };

      let extendOp = await ai.models.generateVideos(extensionPayload);
      while (!extendOp.done) {
        await new Promise((resolve) => setTimeout(resolve, 10000));
        extendOp = await ai.operations.getVideosOperation({ operation: extendOp });
      }
      
      const extendedVideo = extendOp.response?.generatedVideos?.[0]?.video;
      if (extendedVideo) {
        currentVideo = extendedVideo;
        currentVideoDuration += 7; // Increment based on standard extension length
      } else {
        console.warn("Extension operation succeeded but returned no video asset. Stopping extensions.");
        break; 
      }
    }

    const downloadLink = currentVideo?.uri;
    if (downloadLink) {
      const response = await fetch(`${downloadLink}&key=${process.env.API_KEY}`);
      if (!response.ok) throw new Error('Failed to download final production file.');
      
      const blob = await response.blob();
      console.log("Production finalized successfully.");
      return { objectUrl: URL.createObjectURL(blob), blob };
    }
  } catch (error: any) {
    console.error("Gemini Video Production Error:", error);
    throw error;
  }

  throw new Error('Video production failed to complete.');
};

/**
 * Generates audio for a greeting message using Gemini TTS.
 * Returns duration for video synchronization.
 */
export const generateGreetingVoice = async (text: string, voice: VoiceGender): Promise<{ base64: string, duration: number } | null> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
  
  const voiceMap: Record<VoiceGender, string> = {
    [VoiceGender.MALE_TENOR]: 'Kore',
    [VoiceGender.MALE_BASS]: 'Puck',
    [VoiceGender.FEMALE]: 'Charon'
  };

  try {
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash-preview-tts",
      contents: [{ parts: [{ text: `Say warmly: ${text}` }] }],
      config: {
        responseModalities: [Modality.AUDIO],
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: { voiceName: voiceMap[voice] },
          },
        },
      },
    });

    const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    if (!base64Audio) return null;

    const duration = await getAudioDuration(base64Audio);
    return { base64: base64Audio, duration };
  } catch (e) {
    console.error("Voice Generation failed:", e);
    return null;
  }
};
